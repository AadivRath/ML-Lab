{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d31356f",
   "metadata": {},
   "source": [
    "<center><H1> Machine Learning Lab #7\n",
    "\n",
    "<H3>  NAÏVE BAYES CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "101f7dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generic Imports\n",
    "\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7a4949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11753aba",
   "metadata": {},
   "source": [
    "<H2>Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e581359",
   "metadata": {},
   "source": [
    "a) Of the students in the college, 60% of the students reside in the hostel and 40% of the students are day\n",
    "scholars. Previous year results report that 30% of all students who stay in the hostel scored A Grade and 20%\n",
    "of day scholars scored A grade. At the end of the year, one student is chosen at random and found that he/she\n",
    "has an A grade. What is the probability that the student is a hosteler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f70deeba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of hosteller is 0.692.\n"
     ]
    }
   ],
   "source": [
    "#Given:\n",
    "\n",
    "P_hostel = 0.6\n",
    "P_day_scholar = 0.4\n",
    "\n",
    "P_A_given_hostel = 0.3\n",
    "P_A_given_day_scholar = 0.2\n",
    "\n",
    "#To find: P_hostel_given_A\n",
    "\n",
    "\"\"\"\n",
    "Applying Bayes Theorem:\n",
    "\n",
    "P(hostel | A) = P(A|hostel) * P(hostel) / P(A)\n",
    "\n",
    "\n",
    "To complete this we need P(A):\n",
    "\n",
    "P(A) = P(A|Hostel) * P(Hostel) + P(A|DayScholar) * P(DayScholar)\n",
    "P(A) = 0.3 x 0.6 + 0.4 x 0.2\n",
    "P(A) = 0.26\n",
    "\n",
    "Continuing:\n",
    "\n",
    "P(hostel|A) = 0.3 * 0.6 / 0.26\n",
    "= 0.692\n",
    "\"\"\"\n",
    "P_A = 0.3 * 0.6 + 0.4 * 0.2\n",
    "P_hostel_given_A = 0.3 * 0.6 / P_A\n",
    "P_hostel_given_A = round(P_hostel_given_A, 3)\n",
    "\n",
    "print(f\"Probability of hosteller is {P_hostel_given_A}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d712f7",
   "metadata": {},
   "source": [
    "b) Suppose you're testing for a rare disease, and you have the following information:\n",
    "\n",
    "1) The disease has a prevalence of 0.01 (1% of the population has the disease).\n",
    "\n",
    "2) The test is not perfect:\n",
    "\n",
    "3) The test correctly identifies the disease (true positive) 99% of the time (sensitivity).\n",
    "\n",
    "4) The test incorrectly indicates the disease (false positive) 2% of the time (1 - specificity).\n",
    "\n",
    "\n",
    "Calculate the probability of having the disease given a positive test result using Bayes' theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a050b8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of disease is 0.333.\n"
     ]
    }
   ],
   "source": [
    "p_disease = 0.01\n",
    "p_pos_given_disease = 0.99  \n",
    "p_pos_given_no_disease = 0.02\n",
    "\n",
    "p_no_disease = 1 - p_disease\n",
    "\n",
    "p_positive = (p_pos_given_disease * p_disease) + (p_pos_given_no_disease * p_no_disease)\n",
    "\n",
    "numerator = p_pos_given_disease * p_disease\n",
    "p_disease_given_pos = numerator / p_positive\n",
    "p_disease_given_pos = round(p_disease_given_pos, 3)\n",
    "\n",
    "print(f\"Probability of disease is {p_disease_given_pos}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb613aa8",
   "metadata": {},
   "source": [
    "2. Develop a function python code for Naïve Bayes classifier from scratch without using scikit-learn library,\n",
    "to predict whether the buyer should buy computer or not. Consider a following sample training dataset stored\n",
    "in a CSV file containing information about following buyer conditions (such as “<=30,” “medium,” “Yes,”\n",
    "and “fair”) and whether the player played golf (“Yes” or “No”)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbcea1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded (first 3 rows):\n",
      " [['<=30', 'high', 'no', 'fair', 'no'], ['<=30', 'high', 'no', 'excellent', 'no'], ['31...40', 'high', 'no', 'fair', 'yes']]\n"
     ]
    }
   ],
   "source": [
    "#Reading from a docstring instead of a csv because I'm lazy like that lol\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "csv_data = \"\"\"age,income,student,credit_rating,buys_computer\n",
    "<=30,high,no,fair,no\n",
    "<=30,high,no,excellent,no\n",
    "31...40,high,no,fair,yes\n",
    ">40,medium,no,fair,yes\n",
    ">40,low,yes,fair,yes\n",
    ">40,low,yes,excellent,no\n",
    "31...40,low,yes,excellent,yes\n",
    "<=30,medium,no,fair,no\n",
    "<=30,low,yes,fair,yes\n",
    ">40,medium,yes,fair,yes\n",
    "<=30,medium,yes,excellent,yes\n",
    "31...40,medium,no,excellent,yes\n",
    "31...40,high,yes,fair,yes\n",
    ">40,medium,no,excellent,no\"\"\"\n",
    "\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "\n",
    "data = df.values.tolist()\n",
    "\n",
    "features = list(df.columns[:-1])\n",
    "target_name = df.columns[-1]\n",
    "\n",
    "print(\"Data Loaded (first 3 rows):\\n\", data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cde64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.prior_probabilities = {}\n",
    "        self.likelihoods = {}\n",
    "        self.classes = []\n",
    "        self.total_instances = 0\n",
    "        self.target_index = -1\n",
    "\n",
    "    def train(self, data):\n",
    "        self.total_instances = len(data)\n",
    "        self.target_index = len(data[0]) - 1\n",
    "        \n",
    "        class_counts = {}\n",
    "        for row in data:\n",
    "            class_label = row[self.target_index]\n",
    "            class_counts[class_label] = class_counts.get(class_label, 0) + 1\n",
    "        \n",
    "        self.classes = list(class_counts.keys())\n",
    "        \n",
    "        for class_label, count in class_counts.items():\n",
    "            self.prior_probabilities[class_label] = count / self.total_instances\n",
    "\n",
    "        feature_counts = {c: [{} for _ in range(self.target_index)] for c in self.classes}\n",
    "\n",
    "        for row in data:\n",
    "            class_label = row[self.target_index]\n",
    "            for i in range(self.target_index):\n",
    "                feature_value = row[i]\n",
    "                \n",
    "                feature_counts[class_label][i][feature_value] = \\\n",
    "                    feature_counts[class_label][i].get(feature_value, 0) + 1\n",
    "\n",
    "        for class_label in self.classes:\n",
    "            self.likelihoods[class_label] = [{} for _ in range(self.target_index)]\n",
    "            class_total = class_counts[class_label]\n",
    "            \n",
    "            for i in range(self.target_index):\n",
    "                for feature_value, count in feature_counts[class_label][i].items():\n",
    "                    self.likelihoods[class_label][i][feature_value] = count / class_total\n",
    "                    \n",
    "    def predict(self, instance):\n",
    "        posteriors = {} \n",
    "        for class_label in self.classes:\n",
    "            prior = self.prior_probabilities[class_label]\n",
    "            \n",
    "            likelihood = 1.0\n",
    "            for i in range(len(instance)):\n",
    "                feature_value = instance[i]\n",
    "                prob_xi_given_c = self.likelihoods[class_label][i].get(feature_value, 1e-9)\n",
    "                \n",
    "                likelihood *= prob_xi_given_c\n",
    "            \n",
    "            posteriors[class_label] = prior * likelihood\n",
    "\n",
    "        best_class = max(posteriors, key=posteriors.get)\n",
    "        return best_class, posteriors\n",
    "\n",
    "#Training \n",
    "nb_classifier = NaiveBayesClassifier()\n",
    "nb_classifier.train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b96527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prediction Result ---\n",
      "Test Instance: ['<=30', 'medium', 'no', 'excellent']\n",
      "Predicted Class: 'no'\n",
      "Posterior Probabilities: {'no': 0.04114285714285714, 'yes': 0.007054673721340387}\n"
     ]
    }
   ],
   "source": [
    "test_instance = [\"<=30\", \"medium\", \"no\", \"excellent\"]\n",
    "prediction, probabilities = nb_classifier.predict(test_instance)\n",
    "\n",
    "print(f\"\\n--- Prediction Result ---\")\n",
    "print(f\"Test Instance: {test_instance}\")\n",
    "print(f\"Predicted Class: '{prediction}'\")\n",
    "print(f\"Posterior Probabilities: {probabilities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27520ebb",
   "metadata": {},
   "source": [
    "3. Write a Python function to implement the Naive Bayes classifier without using the scikit-learn library for the\n",
    "following sample training dataset stored as a .CSV file.\n",
    "\n",
    "\n",
    "a. Build a classifier that determines whether a text is about sports or not.\n",
    "\n",
    "b. Determine which tag the sentence \"A very close game\" belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7adad476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Not sports|Text): 0.000925925925925926\n",
      "P(Sports|Text): 0.0008329862557267803\n",
      "Prediction for test data: Not sports\n"
     ]
    }
   ],
   "source": [
    "# Sample dataset from the image\n",
    "data = {\n",
    "    'Text': [\"A great game\", \"The election was over\", \"Very clean match\", \n",
    "             \"A clean but forgettable game\", \"It was a close election\"],\n",
    "    'Tag': [\"Sports\", \"Not sports\", \"Sports\", \"Sports\", \"Not sports\"]\n",
    "}\n",
    "\n",
    "# Convert data to a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Function to preprocess the text (lowercase, remove non-alphanumeric characters)\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove non-alphanumeric characters\n",
    "    return text\n",
    "\n",
    "# Simplified Naive Bayes function for a single prediction\n",
    "def naive_bayes_predict(test_example):\n",
    "    # Calculate prior probabilities\n",
    "    total = len(df)\n",
    "    sports_count = len(df[df['Tag'] == 'Sports'])\n",
    "    not_sports_count = len(df[df['Tag'] == 'Not sports'])\n",
    "    \n",
    "    P_sports = sports_count / total\n",
    "    P_not_sports = not_sports_count / total\n",
    "\n",
    "    # Preprocess the test example\n",
    "    test_words = preprocess(test_example).split()\n",
    "\n",
    "    # Calculate likelihoods for each word given 'Sports' and 'Not sports'\n",
    "    P_words_given_sports = 1\n",
    "    P_words_given_not_sports = 1\n",
    "\n",
    "    for word in test_words:\n",
    "        P_word_sports = len(df[(df['Text'].str.contains(word)) & (df['Tag'] == 'Sports')]) / sports_count\n",
    "        P_word_not_sports = len(df[(df['Text'].str.contains(word)) & (df['Tag'] == 'Not sports')]) / not_sports_count\n",
    "\n",
    "        # Add-1 smoothing to avoid zero probabilities\n",
    "        P_words_given_sports *= (P_word_sports + 1) / (sports_count + len(test_words))\n",
    "        P_words_given_not_sports *= (P_word_not_sports + 1) / (not_sports_count + len(test_words))\n",
    "\n",
    "    # Calculate posterior probabilities\n",
    "    P_sports_given_text = P_sports * P_words_given_sports\n",
    "    P_not_sports_given_text = P_not_sports * P_words_given_not_sports\n",
    "\n",
    "    # Predict the class with the higher posterior probability\n",
    "    print(\"P(Not sports|Text):\", P_not_sports_given_text)\n",
    "    print(\"P(Sports|Text):\", P_sports_given_text)\n",
    "    if P_sports_given_text > P_not_sports_given_text:\n",
    "        return \"Sports\"\n",
    "    else:\n",
    "        return \"Not sports\"\n",
    "\n",
    "# Test example to predict\n",
    "test_example = \"A very close game\"\n",
    "\n",
    "# Prediction\n",
    "prediction = naive_bayes_predict(test_example)\n",
    "print(\"Prediction for test data:\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd3a973",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b950f0e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76b31a16",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
